### 一、运行流程和结果

1. 将程序打包成jar包，将NewInstance.txt文件导入到hdfs文件系统根目录下

图片见pdf

2. 输入hadoop jar KMeans-1.jar <簇个数> <迭代次数> <inputpath> <outputpath>，例如hadoop jar KMeans-1.jar 2 3 /NewInstance.txt /2-3 为两个簇、迭代3次。

 

3. 运行结束后输入hadoop fs -get /2-3/points 2-3，将结果导出来

 

4. 运行可视化.py，生成聚类图像，如2-3，详细聚类效果见第三部分

图片见pdf 

 

 

 

### 二、设计思路与所遇问题

首先我构造了两个自定义数据类型Point和Cluster，Point类包含点的信息，Cluster类包含簇的信息，然后主体分为两个mapreduce程序，一个是迭代计算聚类中心，另一个是根据最后生成的聚类中心，标记每个点所属的簇。初始聚类中心就取前k个点。

一开始我自己写了个程序，尝试3个聚类，迭代5次，发现跑出来的结果是这样的



这明显是不对的，我估计是迭代次数不够，把迭代次数改为了10次，结果还是如此

 

把簇的个数改为7，结果仍然是呈横条状分布

 

我用示例程序运行7个簇，结果是比较符合预期的

 

我估计是迭代求中心的部分写错了，因为自己写的非常乱，而且很繁杂，就对照树上的示例程序，把初始生成聚类中心、迭代计算中心的代码进行了替换，但结果还是如此。我又将最后标记每个点的代码改成了示例程序，结果还是错误。结果只能是我自定义的数据类型有问题，但经过反复查看没有发现错误。

于是我在mapper和reducer中输出了每一步得到的结果，查看日志，发现了问题所在：在mapper部分发送的点是对的

 

但是combiner收到的数据却发生了改变

 

这让我很困惑，因为经过代码的替换，我的程序和示例程序是几乎一样的了，应该不会有错误。

最后，我发现了出错的原因：我自定义的点的readFields()和write()不匹配，导致了mapper发送和reducer接受的数据不同。这是一个很蠢的问题，但我对自定义数据类型的理解不够深入，认为这两部分不是很重要，debug时甚至没有检查这两部分，还是费了很大周折才找到了这个问题。

 

### 三、效果分析

见pdf